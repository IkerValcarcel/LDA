{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a382f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from tqdm import tqdm.notebook.tqdm as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240d779",
   "metadata": {},
   "source": [
    "## Se importan los dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93b9346",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'VG-Reviews5AndMetaElecNintSonyMic_v2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m insurances \u001b[38;5;241m=\u001b[39m []   \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#dfMergedfMeta= pd.read_csv('Cell_Phones/SamsungAppleXiaomiReviews_prueba.csv')\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m video_games\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVG-Reviews5AndMetaElecNintSonyMic_v2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m insurances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHRBlockIntuitReviewsTrainDev_vLast7.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'VG-Reviews5AndMetaElecNintSonyMic_v2.csv'"
     ]
    }
   ],
   "source": [
    "# load all metadata\n",
    "#hau nire diskan daukat SAD karpetan 2020-2021\n",
    "\n",
    "video_games = []#\n",
    "insurances = []   \n",
    "#dfMergedfMeta= pd.read_csv('Cell_Phones/SamsungAppleXiaomiReviews_prueba.csv')\n",
    "video_games= pd.read_csv('VG-Reviews5AndMetaElecNintSonyMic_v2.csv')\n",
    "insurances = pd.read_csv('HRBlockIntuitReviewsTrainDev_vLast7.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c616d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_games.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021b42d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "video_games['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5327286",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurances.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurances['brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d878d",
   "metadata": {},
   "source": [
    "## Se obtienen en dataframes aparte las distintas marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNintendo = video_games[video_games['brand'].str.contains('Nintendo',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995cf11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSony = video_games[video_games['brand'].str.contains('Sony|PlayStation|Electr',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMicrosoft = video_games[video_games['brand'].str.contains('[M|m]icrosoft',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96115ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntuit = insurances[insurances['brand'].str.contains('Intuit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c304ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHR = insurances[~insurances['brand'].str.contains('Intuit')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e0f62",
   "metadata": {},
   "source": [
    "## Se separan las reviews negativas y positivas de cada dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa65796",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNintendoPositives=dfNintendo[dfNintendo['overall']>3]\n",
    "dfNintendoNegatives=dfNintendo[dfNintendo['overall']<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61624c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSonyPositives=dfSony[dfSony['overall']>3]\n",
    "dfSonyNegatives=dfSony[dfSony['overall']<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e062310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMicrosoftPositives=dfMicrosoft[dfMicrosoft['overall']>3]\n",
    "dfMicrosoftNegatives=dfMicrosoft[dfMicrosoft['overall']<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIntuitPositives = dfIntuit[dfIntuit['overall']>3]\n",
    "dfIntuitNegatives = dfIntuit[dfIntuit['overall']<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684535e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHRPositives = dfHR[dfHR['overall']>3]\n",
    "dfHRNegatives = dfHR[dfHR['overall']<=3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7158fc",
   "metadata": {},
   "source": [
    "## Se obtienen las text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "nintendoPositivesDocuments = dfNintendoPositives[dfNintendoPositives['reviewText'].notna()]['reviewText'].tolist()\n",
    "nintendoNegativesDocuments = dfNintendoNegatives[dfNintendoNegatives['reviewText'].notna()]['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ae4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonyPositivesDocuments = dfSonyPositives[dfSonyPositives['reviewText'].notna()]['reviewText'].tolist()\n",
    "sonyNegativesDocuments = dfSonyNegatives[dfSonyNegatives['reviewText'].notna()]['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a66c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "microsoftPositivesDocuments = dfMicrosoftPositives[dfMicrosoftPositives['reviewText'].notna()]['reviewText'].tolist()\n",
    "microsoftNegativesDocuments = dfMicrosoftNegatives[dfMicrosoftNegatives['reviewText'].notna()]['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc85b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intuitPositivesDocuments = dfIntuitPositives[dfIntuitPositives['reviewText'].notna()]['reviewText'].tolist()\n",
    "intuitNegativesDocuments = dfIntuitNegatives[dfIntuitNegatives['reviewText'].notna()]['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a0f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HRPositivesDocuments = dfHRPositives[dfHRPositives['reviewText'].notna()]['reviewText'].tolist()\n",
    "HRNegativesDocuments = dfHRNegatives[dfHRNegatives['reviewText'].notna()]['reviewText'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94968efd",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c11086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(H, W, feature_names, documents,output_name, no_top_words = 30, no_top_documents = 10):\n",
    "    f = open(output_name + \".txt\", \"a\")\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        s = \"Topic: \" + str(topic_idx) + \" -->\"\n",
    "        print(s)\n",
    "        f.write(s)\n",
    "        s = ''.join([' ' +feature_names[i] + ' ' + str(round(topic[i], 5)) \n",
    "                for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "        print(s)\n",
    "        f.write(s)\n",
    "        top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "        docProbArray=np.argsort(W[:,topic_idx])\n",
    "        print(docProbArray)\n",
    "    \n",
    "        #for doc_index in top_doc_indices:\n",
    "        #    print(documents[doc_index])\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb600785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa770c",
   "metadata": {},
   "source": [
    "### LDANintPos_31_1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 31\n",
    "\n",
    "alpha = 1.9\n",
    "beta = 1.9\n",
    "\n",
    "documents = nintendoPositivesDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f555c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=no_topics, doc_topic_prior=alpha, topic_word_prior=beta, max_iter=100, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lda_H, lda_W, tf_feature_names, documents, 'LDANintPos_31_1.9')\n",
    "#no_top_words = 30 \n",
    "#no_top_documents = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc82192",
   "metadata": {},
   "source": [
    "### LDANintNeg_26_1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a97f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 26\n",
    "\n",
    "alpha = 1.9\n",
    "beta = 1.9\n",
    "\n",
    "documents = nintendoNegativesDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a971eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=no_topics, doc_topic_prior=alpha, topic_word_prior=beta, max_iter=100, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5110519",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lda_H, lda_W, tf_feature_names, documents, 'LDANintNeg_26_1.9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61a212",
   "metadata": {},
   "source": [
    "### LDASonyPos_34_1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8498b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 34\n",
    "\n",
    "alpha = 1.9\n",
    "beta = 1.9\n",
    "\n",
    "documents = sonyPositivesDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bc8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63187330",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=no_topics, doc_topic_prior=alpha, topic_word_prior=beta, max_iter=100, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3733466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(lda_H, lda_W, tf_feature_names, documents, 'LDASonyPos_34_1.9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aafde3",
   "metadata": {},
   "source": [
    "## GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1050c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproceso(docs):\n",
    "    # Tokenize \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for idx in range(len(docs)):\n",
    "        docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "    # Remove numbers, but not words that contain numbers.\n",
    "    docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "    # Remove words that are only one character.\n",
    "    docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "    docs = [[token for token in doc if not(token in stopwords)] for doc in docs]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "\n",
    "    # Bag-of-words\n",
    "    dictionary = Dictionary(docs)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    print('Number of unique tokens: %d' % len(dictionary))\n",
    "    print('Number of documents: %d' % len(corpus))\n",
    "\n",
    "    return corpus , dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a31c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model(num_topics,corpus, dictionary):\n",
    "    chunksize = 2000\n",
    "    passes = 20\n",
    "    iterations = 400\n",
    "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "    # Make an index to word dictionary.\n",
    "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "    id2word = dictionary.id2token\n",
    "\n",
    "    model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',\n",
    "        eta='auto',\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topics,\n",
    "        passes=passes,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ad1bb",
   "metadata": {},
   "source": [
    "### GensimSonyPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631732a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,dictionary = preproceso(sonyPositivesDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('GensimSonyPos[10-100]' + \".txt\", \"a\")\n",
    "for i in range(10,101):\n",
    "    print(\"Generando modelo: \" + str(i))\n",
    "    model_act=gen_model(i,corpus,dictionary)\n",
    "    top_topics = model_act.top_topics(corpus)\n",
    "    f.write('Modelo con %i clusters -->' % i)\n",
    "    for frec, word in top_topics[0][0]:\n",
    "        f.write(\" \" + word + \" \" + str(frec) + \" |\")\n",
    "    f.write(\"\\n\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78326a0",
   "metadata": {},
   "source": [
    "### GensimSonyNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus,dictionary = preproceso(sonyNegativesDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('GensimSonyNeg[10-100]' + \".txt\", \"a\")\n",
    "for i in range(10,101):\n",
    "    print(\"Generando modelo: \" + str(i))\n",
    "    model_act=gen_model(i,corpus,dictionary)\n",
    "    top_topics = model_act.top_topics(corpus)\n",
    "    f.write('Modelo con %i clusters -->' % i)\n",
    "    for frec, word in top_topics[0][0]:\n",
    "        f.write(\" \" + word + \" \" + str(frec) + \" |\")\n",
    "    f.write(\"\\n\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
